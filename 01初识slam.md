### 相机
- 单目(Monocular)：一个摄像头 --> 单目slam：平移之后才能计算深度信息；估计的轨迹和地图与真实的轨迹和地图相差一个因子，也就是所谓的尺度。单目slam无法仅凭图像确定这个尺度，所以又称为“尺度不确定性”。
- 双目(Stereo)：两个摄像头 --> 双目slam：通过比较左右眼的图像来估计距离，其测量深度范围与两相机间的距离(基线)相关。配置与标定较为复杂，视差计算非常消耗计算资源
- 深度相机(RGB-D)：多个摄像头，能够采集到彩色图片并读取出每个像素与相机之间的距离 --> 通过主动向物体发射并接收返回的光测量物体与相机间的距离，受限于测量范围、噪声干扰、视野小、易受日光干扰等因素，目前主要应用于室内

## 经典视觉slam框架

![image](https://user-images.githubusercontent.com/34792225/181693672-f2ab6685-ea25-46cf-8111-424257891c35.png)

1.<b>传感器信息读取</b>。为相机读取信息及预处理。
2.<b>前端视觉里程计(Visual Odometry, VO)</b>。估算相邻图像间相机的运动，及局部地图的样子。VO又称前端
3.<b>后端(非线性)优化</b>。接收不同时刻视觉里程计测量的相机位姿及回环检测的信息，并对其进行优化，得到全局一致性的轨迹和地图。又称后端
4.<b>回环检测</b>。判断机器人是否到达先前到达过的位置，若检测到回环，他会把信息提供给后端处理。
5.<b>建图</b>。根据估计的轨迹建立与任务要求对应的地图

> 如果把工作环境限定在静态、刚体、光照变化不明显、没有认为干扰的场景，那么这种场景下的slam技术已经相当成熟。

如何从图像中估计出相机运动

### 视觉里程计--相机与空间点的几何关系(前端)

视觉里程计能通过相邻帧间的图像估计相机运动，并恢复场景空间结构。只计算相邻时刻的运动，和过去的信息没有关联。

累计漂移(Accumulating Drift)：视觉里程计在最简单的情况下只估计两个图像间的运动，而每次估计都带有一定的误差，由于里程计的工作方式，先前时刻的误差会传递到下一时刻，经过一段时间后，误差会累计。


### 后端优化(后端)

后端优化主要处理slam过程中的噪声问题，还要关心这个估计带有多大噪声，这些噪声是如何从上一时刻传递到下一时刻的，而我们又对当前估计有多大自信。

后端优化要考虑的问题就是如何从这些带有噪声的数据中估计整个系统的状态(轨迹及地图)，以及这个状态估计的不确定性有多大————最大后验概率估计(Maximum-Posteriori, MAP)

> 在视觉slam中，前端和计算机视觉研究领域更为相关，比如图像的特征提取与匹配等，后端则主要是滤波与非线性优化算法。

> slam问题的本质：<b>对运动主体自身和周围环境空间不确定性的估计</b>


### 回环检测

回环检测主要解决位置估计随时间漂移的问题。例如可以通过判断图像间的相似性来实现。

检测到回环后，将信息传递给后端优化算法。后端根据这些信息把轨迹和地图调整到符合回环检测结果的样子。

这样，如果我们有充分且正确的回环检测，则可以消除累计误差，得到全局一致性的轨迹和地图。


### 建图

- 度量地图：强调精确地表示地图中物体的位置关系
- 拓扑地图：强调地图元素之间的关系


## SLAM问题中的数学表述

时间t离散为t=1,$\cdots$,K。机器人位置为x，则各时刻的位置就为$x_1$,$\cdots$,$x_K$。

运动方程: 

$$ x_k=f\left(x_{k-1}, u_k, w_k\right) \tag {2.1} $$
